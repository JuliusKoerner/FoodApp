{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## information\n",
    "553 ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/julius/Hack/nutrition5k_dataset_nosides/metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoFeatureExtractor, SwinForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = image.resize((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/envs/venv/lib/python3.12/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/swin-base-patch4-window7-224\")\n",
    "model = SwinForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinForImageClassification(\n",
       "  (swin): SwinModel(\n",
       "    (embeddings): SwinEmbeddings(\n",
       "      (patch_embeddings): SwinPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): SwinEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-17): 18 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (downsample): SwinPatchMerging(\n",
       "            (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinStage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x SwinLayer(\n",
       "              (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (attention): SwinAttention(\n",
       "                (self): SwinSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): SwinSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (drop_path): SwinDropPath(p=0.1)\n",
       "              (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (intermediate): SwinIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): SwinOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/envs/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/julius/anaconda3/envs/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/julius/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:28<00:00, 3.58MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "# Load the pretrained model\n",
    "model = resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Prepare an image transform pipeline\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),  # Resize images to match model input size\n",
    "    ToTensor(),  # Convert images to PyTorch tensors\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoFeatureExtractor, SwinForImageClassification\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_im = '~/Hack/nutrition5k_dataset_nosides/metadata/cafe1_own.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_im)\n",
    "df.columns = ['id', 'calories', 'mass', 'fat', 'carb', 'protein']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>calories</th>\n",
       "      <th>mass</th>\n",
       "      <th>fat</th>\n",
       "      <th>carb</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dish_1562688426</td>\n",
       "      <td>137.569992</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8.256000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>10.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dish_1561662054</td>\n",
       "      <td>419.438782</td>\n",
       "      <td>292.0</td>\n",
       "      <td>23.838249</td>\n",
       "      <td>26.351543</td>\n",
       "      <td>25.910593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dish_1562008979</td>\n",
       "      <td>382.936646</td>\n",
       "      <td>290.0</td>\n",
       "      <td>22.224644</td>\n",
       "      <td>10.173570</td>\n",
       "      <td>35.345387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dish_1560455030</td>\n",
       "      <td>20.590000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dish_1558372433</td>\n",
       "      <td>74.360001</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>20.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>dish_1551139192</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>8.190000</td>\n",
       "      <td>0.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>dish_1563382911</td>\n",
       "      <td>182.040009</td>\n",
       "      <td>123.0</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>1.968000</td>\n",
       "      <td>12.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>dish_1562691737</td>\n",
       "      <td>485.676880</td>\n",
       "      <td>700.0</td>\n",
       "      <td>11.722251</td>\n",
       "      <td>70.597321</td>\n",
       "      <td>27.926394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>dish_1558458496</td>\n",
       "      <td>53.130001</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>13.860001</td>\n",
       "      <td>0.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>dish_1568664931</td>\n",
       "      <td>67.877647</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.474706</td>\n",
       "      <td>2.107843</td>\n",
       "      <td>1.279608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4767 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id    calories   mass        fat       carb    protein\n",
       "0     dish_1562688426  137.569992   88.0   8.256000   5.190000  10.297000\n",
       "1     dish_1561662054  419.438782  292.0  23.838249  26.351543  25.910593\n",
       "2     dish_1562008979  382.936646  290.0  22.224644  10.173570  35.345387\n",
       "3     dish_1560455030   20.590000  103.0   0.148000   4.625000   0.956000\n",
       "4     dish_1558372433   74.360001  143.0   0.286000   0.429000  20.020000\n",
       "...               ...         ...    ...        ...        ...        ...\n",
       "4762  dish_1551139192   31.500000   63.0   0.063000   8.190000   0.315000\n",
       "4763  dish_1563382911  182.040009  123.0  13.530000   1.968000  12.300000\n",
       "4764  dish_1562691737  485.676880  700.0  11.722251  70.597321  27.926394\n",
       "4765  dish_1558458496   53.130001   77.0   0.154000  13.860001   0.539000\n",
       "4766  dish_1568664931   67.877647   60.0   6.474706   2.107843   1.279608\n",
       "\n",
       "[4767 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def prepare_image(image_path, target_size=(224,224)):\n",
    "    \"\"\"\n",
    "    Load an image file and prepare it for model prediction.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = image.resize(target_size)\n",
    "    \n",
    "    # Convert the image to a numpy array and normalize it\n",
    "    image = np.array(image) / 255.0\n",
    "    \n",
    "    # Ensure it's in the right shape (batch size, height, width, channels)\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/home/julius/Hack/nutrition5k_dataset_nosides/imagery/realsense_overhead/dish_1558458496/rgb.png'\n",
    "image = Image.open(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = None\n",
    "df['depth'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4767it [01:50, 43.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "basepath = '/home/julius/Hack/nutrition5k_dataset_nosides/imagery/realsense_overhead/'\n",
    "images = []\n",
    "depths = []\n",
    "data = []\n",
    "for line, id in tqdm(enumerate(df['id'].values)):\n",
    "    p = basepath + id + '/rgb.png'\n",
    "    if os.path.exists(basepath + id + '/rgb.png'):\n",
    "        images.append(prepare_image(p))\n",
    "        depths.append(prepare_image(basepath + id + '/depth_color.png'))\n",
    "        data.append(line)\n",
    "        #d['depth'] = Image.open(basepath + id + '/depth_color.png')\n",
    "    \"\"\"p = basepath + id + '/depth_color.png'\n",
    "    if os.path.exists(p):\n",
    "        df.loc[line, 'depth'] = [np.array(Image.open(p))]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3261, 224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths = np.array(depths)\n",
    "depths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Store df to file\n",
    "with open('df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "# Store images to file\n",
    "with open('images.pkl', 'wb') as f:\n",
    "    pickle.dump(images, f)\n",
    "\n",
    "# Store depths to file\n",
    "with open('depths.pkl', 'wb') as f:\n",
    "    pickle.dump(depths, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3261, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/Hack/nutrition5k_dataset_nosides/metadata/ingredients_metadata.csv'\n",
    "incr = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish_1561662216    dish_1562688426\n",
      "300.794281              137.569992\n",
      "193.000000                    88.0\n",
      "12.387489                    8.256\n",
      "28.218290                     5.19\n",
      "                        ...       \n",
      "3.414345                       NaN\n",
      "4.06307055                     NaN\n",
      "0.03414345                     NaN\n",
      "0.809199765                    NaN\n",
      "0.119502075                    NaN\n",
      "Name: 0, Length: 125, dtype: object\n",
      "9\n",
      "16\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74467/3788652929.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dishes.append(row[0])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'nan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(row\u001b[38;5;241m.\u001b[39miloc[i] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 20\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(row\u001b[38;5;241m.\u001b[39miloc[i])\n\u001b[1;32m     22\u001b[0m     array[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39miloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:])] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'nan'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '~/Hack/nutrition5k_dataset_nosides/metadata/dish_metadata_cafe1.csv'\n",
    "# Read the CSV file row by row\n",
    "chunk_size = 1\n",
    "df_chunks = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "\n",
    "# Initialize a dictionary to hold the data\n",
    "data = {'Dish Number': [], 'Ingredient Mass': []}\n",
    "dishes = []\n",
    "# Loop through each chunk (row)\n",
    "rows = []\n",
    "for chunk in df_chunks:\n",
    "    array = np.zeros(555).astype(float)\n",
    "    row = chunk.iloc[0]  # Get the row as a Series\n",
    "    print(row)\n",
    "    dishes.append(row[0])\n",
    "    i = 9\n",
    "    while(row.iloc[i] != 'nan'):\n",
    "        print(i)\n",
    "        pos = int(str(row.iloc[i-3])[-4:])\n",
    "        value = float(row.iloc[i])\n",
    "        array[int(str(row.iloc[i-3])[-4:])] = value\n",
    "        i = i+7\n",
    "    rows.append(array)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
